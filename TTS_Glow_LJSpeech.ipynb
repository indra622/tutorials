{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9645dd2c-95fd-491f-8229-5e807c9e0fd3",
   "metadata": {},
   "source": [
    "LJSpeech Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe9d1d-246a-447c-8636-556103cec27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c 'from TTS.utils.downloaders import download_ljspeech; download_ljspeech(\"../recipes/ljspeech/\");'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb18b121-8b0c-45e5-b454-57fe7aeef792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Trainer: Where the âœ¨ï¸ happens.\n",
    "# TrainingArgs: Defines the set of arguments of the Trainer.\n",
    "from trainer import Trainer, TrainerArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b9be1a-6e08-4b06-bfcd-14c9261545a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GlowTTSConfig: all model related values for training, validating and testing.\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d62a564-2465-4d20-a724-4c0351435626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the same path as this script as our training folder.\n",
    "#output_path = os.path.dirname(os.path.abspath(__file__))\n",
    "output_path = os.path.join(os.getcwd(), \"../recipes/ljspeech/\")\n",
    "\n",
    "# DEFINE DATASET CONFIG\n",
    "# Set LJSpeech as our target dataset and define its path.\n",
    "# You can also use a simple Dict to define the dataset and pass it to your custom formatter.\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29762a46-af8a-4f8f-b469-c32f86b49ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE THE TRAINING CONFIGURATION\n",
    "# Configure the model. Every config class inherits the BaseTTSConfig.\n",
    "config = GlowTTSConfig(\n",
    "    batch_size=32,\n",
    "    eval_batch_size=16,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=1000,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66d275a-7bb5-4dff-a713-3c991f1d103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE THE AUDIO PROCESSOR\n",
    "# Audio processor is used for feature extraction and audio I/O.\n",
    "# It mainly serves to the dataloader and the training loggers.\n",
    "ap = AudioProcessor.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d323cf10-f959-40b8-8473-3f04bbe5a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE THE TOKENIZER\n",
    "# Tokenizer is used to convert text to sequences of token IDs.\n",
    "# If characters are not defined in the config, default characters are passed to the config\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3bb8fac-640b-4561-9abc-ce0ebbf18f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 13100 files in /docker_vol/recipes/ljspeech/LJSpeech-1.1\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA SAMPLES\n",
    "# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
    "# You can define your custom sample loader returning the list of samples.\n",
    "# Or define your custom formatter and pass it to the `load_tts_samples`.\n",
    "# Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd09aed-54d1-49da-a502-8c1f993eb90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# INITIALIZE THE MODEL\n",
    "# Models take a config object and a speaker manager as input\n",
    "# Config defines the details of the model like the number of layers, the size of the embedding, etc.\n",
    "# Speaker manager is used by multi-speaker models.\n",
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d0c1bad-0f7a-4e8d-8e8c-d9ae8280f685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 2\n",
      " | > Num. of GPUs: 6\n",
      " | > Num. of CPUs: 48\n",
      " | > Num. of Torch Threads: 24\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=/docker_vol/tutorials/../recipes/ljspeech/run-September-03-2024_04+49AM-f75b4d8\n",
      "/usr/local/lib/python3.10/dist-packages/trainer/trainer.py:552: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n",
      "\n",
      " > Model has 28610257 parameters\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE THE TRAINER\n",
    "# Trainer provides a generic API to train all the ðŸ¸TTS models with all its perks like mixed-precision training,\n",
    "# distributed training, etc.\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples, gpu=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414a5f5-df28-46bf-af96-4742df161181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> /docker_vol/tutorials/../recipes/ljspeech/run-September-03-2024_04+49AM-f75b4d8\n",
      "\n",
      "\u001b[1m > TRAINING (2024-09-03 06:10:50) \u001b[0m\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_487004_589613263_0>: No space left on device (28)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_487100_4210615097_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_486951_3237173319_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_487052_2002290989_0>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_487004_1005819446_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_487100_1857842621_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_486951_392992042_1>: No space left on device (28)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 558, in reduce_storage\n",
      "    metadata = storage._share_filename_cpu_()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 337, in wrapper\n",
      "    return fn(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/storage.py\", line 411, in _share_filename_cpu_\n",
      "    return super()._share_filename_cpu_(*args, **kwargs)\n",
      "RuntimeError: unable to write to file </torch_487052_26537771_1>: No space left on device (28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# AND... 3,2,1... ðŸš€\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d4633-0c13-4f3d-87bf-ff03a852e192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
