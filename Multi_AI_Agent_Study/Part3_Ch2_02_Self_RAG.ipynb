{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHD0yUrF9WnXSC8Szn+Tst",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indra622/tutorials/blob/master/Multi_AI_Agent_Study/Part3_Ch2_02_Self_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc6-7XvS7xWw",
        "outputId": "ea6aaad0-d5cd-4968-aceb-e0ce27fdc5cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/149.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m143.4/149.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-community langchain-openai python-dotenv chromadb langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFYL2KiTDf97",
        "outputId": "21fd1e66-f5f6-4398-cdc6-a08c2f6b17a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0\n",
        ")\n",
        "\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=OpenAIEmbeddings(),\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JzOmxmJODtas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "class GradeDocuments(BaseModel):\n",
        "  \"\"\" Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "  binary_score: str = Field(\n",
        "      description = \"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "  )\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "system = \"\"\"\n",
        "  You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "  It does not need to be a stringent test. The goal is to filter out erropneous retrievals. \\n\n",
        "  If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "  Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
        "  \"\"\"\n",
        "\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\" ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_grader = grade_prompt | structured_llm_grader\n",
        "question = 'agent memory'\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ4VhIvOG1sl",
        "outputId": "218e8a0a-3bea-4cff-b452-97bc8f26da53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "<ipython-input-10-05ac5e551402>:31: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(question)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = hub.pull('rlm/rag-prompt')\n",
        "\n",
        "llm = ChatOpenAI(model_name = 'gpt-4o-mini', temperature=0)\n",
        "\n",
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(generation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3eVRaOWMkAG",
        "outputId": "acf3d805-da1a-4e34-83f3-cb6220302878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent memory in LLM-powered autonomous systems consists of short-term and long-term memory. Short-term memory involves in-context learning, while long-term memory allows agents to retain and recall information over extended periods, often using an external vector store for fast retrieval. This memory structure enables agents to improve their performance by learning from past experiences and interactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GradeHallucinations(BaseModel):\n",
        "  \"\"\" Binary score for hallucination present in generation answer.\"\"\"\n",
        "\n",
        "  binary_score: str = Field(\n",
        "      description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
        "  )\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
        "\n",
        "system = \"\"\"\n",
        "  You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
        "  Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
        "\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
        "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiMq6N3qZz4u",
        "outputId": "00705689-099e-4726-f352-04ac7b4767ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradeHallucinations(binary_score='yes')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GradeAnswer(BaseModel):\n",
        "  \"\"\" Binary score to assess answer addresses question.\"\"\"\n",
        "\n",
        "  binary_score: str = Field(\n",
        "      description=\"Answer addresses the question, 'yes' or 'no'\"\n",
        "  )\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0)\n",
        "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
        "\n",
        "system = \"\"\"\n",
        "  You are a grader assessing whether an answer addresses / resolves a question \\n\n",
        "  Give a binary score 'yes' or 'no'. 'Yes' means that the answer resolves the question. \"\"\"\n",
        "\n",
        "answer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "answer_grader = answer_prompt | structured_llm_grader\n",
        "answer_grader.invoke({\"question\": question, \"generation\": generation})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjAn3GfhbMT3",
        "outputId": "aac0bcdb-2e73-4b88-882f-f9f2983775e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradeAnswer(binary_score='yes')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)\n",
        "\n",
        "system = \"\"\"\n",
        "  You are a question re-writer that converts an input question to a better version that is optimized \\n\n",
        "  for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
        "\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
        "question_rewriter.invoke({'question': question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ts6yiyZ2ckgT",
        "outputId": "e218dd52-af51-4072-b1d4-1225a7659bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What are the key concepts and applications of agent memory in artificial intelligence?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from typing import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  \"\"\"\n",
        "  Represents the state of our graph.\n",
        "\n",
        "  Attributes:\n",
        "    question: question\n",
        "    generation: LLM generation\n",
        "    documents: list of documents\n",
        "  \"\"\"\n",
        "\n",
        "  question: str\n",
        "  generation: str\n",
        "  documents: List[str]"
      ],
      "metadata": {
        "id": "oomlCPa-gv46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def retrieve(state):\n",
        "  \"\"\"\n",
        "  Retrieve documents\n",
        "\n",
        "  Args:\n",
        "    state (dict): The current graph state\n",
        "\n",
        "  Returns:\n",
        "    state (dict): New key added to state, documents, that contains retrieved documents\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---RETRIEVE---\")\n",
        "  question = state[\"question\"]\n",
        "\n",
        "  documents = retriever.get_relevant_documents(question)\n",
        "\n",
        "  return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "def generate(state):\n",
        "\n",
        "  \"\"\"\n",
        "  Generate answer\n",
        "\n",
        "  Args:\n",
        "    state (dict): The current graph state\n",
        "\n",
        "  Returns:\n",
        "    state (dict): New key added to state, generation, that contains LLM generation\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---GENERATE---\")\n",
        "  question = state[\"question\"]\n",
        "  documents = state['documents']\n",
        "\n",
        "  generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "\n",
        "  return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "\n",
        "\n",
        "def grade_documents(state):\n",
        "  \"\"\"\n",
        "  Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "  Args:\n",
        "    state (dict): The current graph state\n",
        "\n",
        "  Returns:\n",
        "    state (dict): New key added to state, binary_score, that contains binary score\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "  question = state[\"question\"]\n",
        "  documents = state[\"documents\"]\n",
        "\n",
        "  filtered_docs = []\n",
        "\n",
        "  for d in documents:\n",
        "    score = retrieval_grader.invoke(\n",
        "        {\"question\": question, \"document\": d.page_content}\n",
        "    )\n",
        "\n",
        "\n",
        "    grade = score.binary_score\n",
        "\n",
        "    if grade == 'yes':\n",
        "      print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "      filtered_docs.append(d)\n",
        "\n",
        "    else:\n",
        "      print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "      continue\n",
        "\n",
        "  return {\"documents\": filtered_docs, \"question\": question}\n",
        "\n",
        "\n",
        "def transform_query(state):\n",
        "  \"\"\"\n",
        "  Transform the query to produce a better question.\n",
        "\n",
        "  Args:\n",
        "    state (dict): The current graph state\n",
        "\n",
        "  Returns:\n",
        "    state (dict): Updates question key with a re-phrased question\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---TRANFORM QUERY---\")\n",
        "  question = state[\"question\"]\n",
        "  documents = state[\"documents\"]\n",
        "\n",
        "  better_question = question_rewriter.invoke({\"question\": question})\n",
        "\n",
        "  return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "\n",
        "\n",
        "def decide_to_generate(state):\n",
        "  \"\"\"\n",
        "  Determines whether to generate an answer, or re-generate a question\n",
        "\n",
        "  Args:\n",
        "    state (dict): The current graph state\n",
        "\n",
        "  Returns:\n",
        "    str: Binary decision for next node to call\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "  #state[\"question\"]\n",
        "  filtered_documents = state[\"documents\"]\n",
        "\n",
        "  if not filtered_documents:\n",
        "    print(\n",
        "        \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
        "    )\n",
        "    return \"transform_query\"\n",
        "  else:\n",
        "    print(\"---DECISION: GENERATE---\")\n",
        "    return \"generate\"\n",
        "\n",
        "\n",
        "def grade_generation_v_documents_and_question(state):\n",
        "  \"\"\"\n",
        "  Determines whether the generation is grounded in the document and answers question.\n",
        "\n",
        "  Args:\n",
        "    state (dict): The current graph state\n",
        "\n",
        "  Returns:\n",
        "    state (dict): New key added to state, binary_score, that contains binary score\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"---CHECK HALLUCINATIONS---\")\n",
        "\n",
        "  question = state[\"question\"]\n",
        "  documents = state[\"documents\"]\n",
        "  generation = state[\"generation\"]\n",
        "\n",
        "  score = hallucination_grader.invoke(\n",
        "      {\"documents\": documents, \"generation\": generation}\n",
        "  )\n",
        "  grade = score.binary_score\n",
        "\n",
        "  if grade == \"yes\":\n",
        "    print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
        "\n",
        "    print(\"---GRADE GENERATION vs QUESTION---\")\n",
        "\n",
        "    score = answer_grader.invoke(\n",
        "        {\"question\": question, \"generation\": generation}\n",
        "    )\n",
        "\n",
        "    grade = score.binary_score\n",
        "\n",
        "    if grade == \"yes\":\n",
        "      print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
        "      return \"useful\"\n",
        "    else:\n",
        "      print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
        "      return \"not useful\"\n",
        "  else:\n",
        "    print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
        "    return \"not supported\"\n"
      ],
      "metadata": {
        "id": "py588IcQiiWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "workflow.add_node(\"retrieve\", retrieve)\n",
        "workflow.add_node(\"grade_documents\", grade_documents)\n",
        "workflow.add_node(\"generate\", generate)\n",
        "workflow.add_node(\"transform_query\", transform_query)\n",
        "\n",
        "workflow.add_edge(START, \"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    grade_generation_v_documents_and_question,\n",
        "    {\n",
        "        \"useful\": \"generate\",\n",
        "        \"not useful\": END,\n",
        "        \"not supported\": \"transform_query\",\n",
        "    },\n",
        ")\n",
        "\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "XyRi9lNguerQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "try:\n",
        "  display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "WNYa21Ufwbof",
        "outputId": "779268fe-754c-442d-ae14-57d2acff1cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "inputs = {'question': \"explain how the different types of agent memory work?\"}\n",
        "\n",
        "for output in app.stream(inputs):\n",
        "  for key, value in output.items():\n",
        "    print(f\"Node {key}:\")\n",
        "\n",
        "  print(\"\\n---\\n\")\n",
        "\n",
        "\n",
        "print(value['generation'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CD2oyEnTw2Wy",
        "outputId": "6ad65efb-0dec-4512-e27b-c683a4adc97b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVE---\n",
            "Node retrieve:\n",
            "\n",
            "---\n",
            "\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: GENERATE---\n",
            "Node grade_documents:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "Node generate:\n",
            "\n",
            "---\n",
            "\n",
            "---GENERATE---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-ac264bed3b17>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"explain how the different types of agent memory work?\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Node {key}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 )\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-6b995d74ec4d>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'documents'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0mgeneration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrag_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"documents\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"generation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3014\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3015\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3016\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3017\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m         return cast(\n\u001b[1;32m    283\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    859\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 results.append(\n\u001b[0;32m--> 690\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    691\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    926\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             response = self._client.send(\n\u001b[0m\u001b[1;32m    997\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdYrbN2jxPNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}